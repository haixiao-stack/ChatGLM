{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "607a77a9-7d5e-436d-8a29-baa740e6bfba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import TrainingArguments,TrainerCallback\n",
    "from transformers import Trainer, HfArgumentParser\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from dataclasses import dataclass, field\n",
    "import datasets\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b9345f-613e-41e1-8334-ed4e3bf36c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(tokenizer, config, example, max_seq_length):\n",
    "    #问题\n",
    "    prompt = example[\"context\"]\n",
    "    #答案\n",
    "    target = example[\"target\"]\n",
    "    #问题分词\n",
    "    prompt_ids = tokenizer.encode(prompt, max_length=max_seq_length, truncation=True)\n",
    "    #答案分词\n",
    "    target_ids = tokenizer.encode(\n",
    "        target,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False)\n",
    "    input_ids = prompt_ids + target_ids + [config.eos_token_id]\n",
    "    #input_ids:问题分词+答案分词  seq_len:问题长度\n",
    "    return {\"input_ids\": input_ids, \"seq_len\": len(prompt_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac320d5-da1a-4d19-b9f3-02d723a6fa5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"/root/autodl-tmp/model/\"\n",
    "model_name = \"chatglm\"\n",
    "model_path = os.path.join(model_dir,model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path,trust_remote_code=True) #导入分词器\n",
    "config = transformers.AutoConfig.from_pretrained(model_path, trust_remote_code=True, device_map='auto') #导入模型配置\n",
    "def read_jsonl(path, max_seq_length, skip_overlength=False):\n",
    "    with open(path, \"r\",encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            example = json.loads(line)\n",
    "            feature = preprocess(tokenizer, config, example, max_seq_length)\n",
    "            if skip_overlength and len(feature[\"input_ids\"]) > max_seq_length:\n",
    "                continue\n",
    "            feature[\"input_ids\"] = feature[\"input_ids\"][:max_seq_length]\n",
    "            yield feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5bb5402-04b8-4885-b30f-92b6da161939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9787ede7515646e1bc8a60b3b4bb6f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2956 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = \"/root/autodl-tmp/data/wenlv/\"\n",
    "json_name = \"wenlv.jsonl\"\n",
    "save_name = \"wenlv_token\"\n",
    "json_path = os.path.join(data_dir,json_name)\n",
    "save_path = os.path.join(data_dir,save_name)\n",
    "max_seq_length = 300\n",
    "skip_overlength = False\n",
    "dataset = datasets.Dataset.from_generator(lambda: read_jsonl(json_path, max_seq_length, skip_overlength))\n",
    "dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a01ad5c-b940-47fd-92b2-29b00c0d849b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
